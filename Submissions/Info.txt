** Try 1 **
Method: Random Forests
Description: Random Forests using all variables. 
Seed(1) for splitting train-test set 
Seed(2e4) for RF
Score: 0.49244
***********

** Try 2 **
Method: Random Forests
Description: All variables except the pressure (At this point didnt know what the labels were so i dropped the variables)
Score: 0.36988
***********

** Try 3 **
Method:CART @ 0.01, using top 12 predictors from RF
Description: Using the most significant (top 12 of imporance plot) variables from the RF model, create a CART model with cp= 0.01
Score: 0.34910
***********

** Try 4 **
Method:CART + manual
Description: Same output as above, but merged with output from 1.
Score: 0.46177
***********

** Try 5 **
Method: RF + manual
Description: Using output of 1, manually remove flags that seem out of place (random TRUE amongst FALSE and vice versa)
Score: 0.50374
***********

** Try 6 **
Method: Normal Distribution
Description: Flag variables that are greater than 3sd Deviation from Normal of Dataset1 + join with Try1 data + remove stray flags
Score: 0.76108
***********

** Try 7 **
Method: Normal Distribution + Moving Averages
Description: Do a 5-window EMA to smoothen the values of the dataset, then run it through the normal dist code for try6.
Score: 0.72659
***********

** Try 8 **
Method: Normal Dist + Centered MA
Description: 2-sided Moving average of window size 5 to smoothen data. Use norm dist mtd to flag out points > 3SD from Mean (mean and sd values learned from dataset 1)
Score: 0.72885
***********

** Try 9 **
Method: Normal Dist + One-sided MA
Description: A one sided MA is better for predictive analysis. This is the exact same code for Try 7 except with a smaller window (of size 3)
Score: 0.73067
***********

** Try 10 **
Method: RX's Deep Learning
Description: Need to ask her
Score: 0.57005
***********

** Try 11 **
Method: Normal Distribution
Description: Same as Try 6, without edits
Score: 0.65468
***********

** Try 12 **
Method: RF + Norm Dist
Description: Using the results from RF and Norm Dist, we combine them into a unified prediction. Here we assume that RF can accurately predict attacks that are trained in dataset2 and will be used to correct the false negatives (for those attacks) in the norm dist model
Score: 0.75092
***********

** Try 13 **
Method: RF + Norm Dist + Merge Disjoint Predictions
Description: Same as above, but run through all predictions, merging pockets of TRUE within a proximity to 1 block while removing isolated pockets.
Score: 0.81417
***********

** Try 14 **
Method: 
Description:
Score: 
***********





